<html>
<head>
<style type="text/css">
body
{
	font-family: Arial;
}
</style>
</head>

<body>
<style type="text/css">
.mytable{
width:800px;
height:100px;
margin:0 auto;
border-collapse: collapse;

}
</style>

<table class="mytable" bordercolor="#EEEEE6" border="1">
  <tr>
    <th></th>
    <th><br> <h2 align="center">A new OCTA Image dataset for Segmentation in Diabetic Retinopathy
</h2></th>
	<td></td>
  </tr>
  
  <tr>
    <td></td>
    <td ><br>--------------------------------------------------------------------------------------------------------------------------------------------<br>
<br>  Pyramid maps Attention-based Convolutional neural Network (PACN) model for segmentation  2022.9.6.,
<br>  Permission to use copy, or modify this dataset, tool and codes for educational and research purposes.
<br>  E-mail : mafei0603（at）163.com ; 17861318579（at）163.com 
<br>  Homepage : https://17861318579.github.io/LPBC
<br>--------------------------------------------------------------------------------------------------------------------------------------------<br><br> 
<b>1. Dataset Description </b>
<br> 
<p style=text-align:justify; text-justify:inter-ideograph;> 
Our dataset is based on the OCTA technique, by using the SS-OCT system to obtain the eye images of 106 diabetic patients. All DR images are annotated by experienced doctors. To protect the privacy of patients, the information of DR images is anonymous during the construction of the DR dataset. According to the characteristics of OCTA images, we can check out the blood vessels in the retinal and choroid layers based on OCTA images. Retinal vascular layers are not easily distinguished due to the appearance of complex structures in ocular tissue features. Thus, we can determine the boundaries of the retinal layers with the inner limiting membrane (ILM), nerve fiber layer (NFL), ganglion cell layer (GCL), inner plump layer (IPL), inner nuclear layer (INL), outer plump layer (OPL), retinal pigment epithelium (NFL), and Bruch's membrane (BM). However, the regions of DR lesions in our study often appear in the superficial layer of retina. To segment DR lesions clearly, we select the retinal layer, the inner retinal layer and the superficial blood vessel layer to segment DR lesions. The data-set is captured by wide-field OCTA(WF-OCTA). The DR dataset contains pixel-level labels and image-level labels of 1024 $\times$ 1024 pixels. 
<br>  This dataset will be soon released publicly. The ground-truth samples were manually made by our experts, which are aided with our self-developed software. 
<br>
<br>
</p>
</td>
	<td></td>
  </tr>
   <tr>
    <td></td>
	<td>
 
</td>
    <td>
	
</td>
  </tr>
   <tr>
    <td></td>
	
    <td><b>2. Application Tool and code Download </b>
<br><br>
2.1 <font color="#FF0000">The making ground-truth tool </font> developed by our team can be downloaded with URL：<a href="MakeGroundTruth_v1.01.zip">MakeGroundtruthTool_v1.01 (windows desktop app at .netframework2.0)</a>.This software is a specialized tool to make the ground truth from original samples under complex scene. The ground-truth images can be obtained by this tool with the help in Fig.2, which is developed by our team. This application is run under <a href="https://download.microsoft.com/download/9/8/6/98610406-c2b7-45a4-bdc3-9db1b1c5f7e2/NetFx20SP1_x64.exe">.netframework2.0(win-x64)</a> with windows 10 (x86 or x64).
<br><br>
2.2 The ground-truth tool developed by our team can be downloaded with URL：<a href="MakeGroundtruthTool_v1.rar">MakeGroundtruthTool_v1.0 (windows desktop app at .net 5.0)</a>.This software is a specialized tool to make the ground truth from original samples under complex scene. The ground-truth images can be obtained by this tool with the help in Fig.2, which is developed by our team. This application is run under <a href="https://download.visualstudio.microsoft.com/download/pr/0393fb31-b54e-4325-ba45-2b682fd6a43d/90036afbb9671be618554bf8fae3f66f/windowsdesktop-runtime-5.0.11-win-x86.exe">.net 5.0 runtime(win-x86)</a> with windows 10 (x86 or x64).
<br><br>
2.3 The <b> key code of our approach (PACN) </b>for demo can be downloaded <a href="Demo_LPBC.rar">here</a> (Pytorch).<br>    
<br>
2.4 The code of U-Net for demo can be downloaded <a href="https://github.com/Andy-zhujunwen/U-Net-ZOO">here</a>  (Pytorch).
<br>
<br>
</td>
  <td>
	 
	</td>
	</tr>
	 <tr>
    <td></td>
	<td>
 <br><br>--------------------------------------------------------------------------------------------------------------------------------------------<br>
<h4 align="center">FIGURE 1 The thumbnail view of the Dataset for nonperfusion areas</h4> <br>
<b>The Original Image </b>
<img src="image_4_5.jpg" width="800" />
<br>
<b>The Ground-truth </b>
<img src="label_4_5.jpg" width="800" />
<br>
<br><br>--------------------------------------------------------------------------------------------------------------------------------------------<br>
<h4 align="center">FIGURE 2 The help for the ground-truth tool(MakeGT, it can make GT for several types of scenes.)</h4> <br>
<img src="Help1.jpg"  width="800" />
<br>
<img src="help.png"  width="800" />
<br>
</td>
    <td>
	<a href="https://clustrmaps.com/site/1bobi"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=QoRYI9AoBD5uM3C9pbBm79T2pX0DSdkJY0iUGEq46eY&cl=ffffff" width="1" height="1" /></a>
</td>
  </tr>
</table>
 

</body>
</html>
